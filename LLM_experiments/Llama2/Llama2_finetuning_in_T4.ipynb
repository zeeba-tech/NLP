{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"def clear_cache():\n  if torch.cuda.is_available():\n    model = None\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-09-04T19:27:15.307215Z","iopub.execute_input":"2023-09-04T19:27:15.307551Z","iopub.status.idle":"2023-09-04T19:27:15.316531Z","shell.execute_reply.started":"2023-09-04T19:27:15.307520Z","shell.execute_reply":"2023-09-04T19:27:15.314360Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2023-09-04T19:26:05.307275Z","iopub.execute_input":"2023-09-04T19:26:05.307650Z","iopub.status.idle":"2023-09-04T19:26:08.997880Z","shell.execute_reply.started":"2023-09-04T19:26:05.307615Z","shell.execute_reply":"2023-09-04T19:26:08.996841Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**Install Ludwig from the latest release**","metadata":{}},{"cell_type":"code","source":"!pip install ludwig[llm]","metadata":{"execution":{"iopub.status.busy":"2023-09-04T19:26:20.355492Z","iopub.execute_input":"2023-09-04T19:26:20.355955Z","iopub.status.idle":"2023-09-04T19:27:15.303010Z","shell.execute_reply.started":"2023-09-04T19:26:20.355924Z","shell.execute_reply":"2023-09-04T19:27:15.301714Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting ludwig[llm]\n  Downloading ludwig-0.8.2.tar.gz (992 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m992.5/992.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: Cython>=0.25 in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (0.29.35)\nRequirement already satisfied: h5py!=3.0.0,>=2.6 in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (3.9.0)\nRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (1.23.5)\nRequirement already satisfied: pandas!=1.1.5,>=1.0 in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (2.0.2)\nRequirement already satisfied: scipy>=0.18 in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (1.11.2)\nRequirement already satisfied: tabulate>=0.7 in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (0.9.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (1.2.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (4.66.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (2.0.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (2.0.1)\nRequirement already satisfied: torchtext in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (0.15.1)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (0.15.1)\nRequirement already satisfied: pydantic<2.0 in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (1.10.9)\nCollecting transformers<4.32.0,>=4.31.0 (from ludwig[llm])\n  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tokenizers>=0.13.3 in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (0.13.3)\nRequirement already satisfied: spacy>=2.3 in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (3.6.1)\nRequirement already satisfied: PyYAML!=5.4.*,<6.0.1,>=3.12 in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (6.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (1.4.0)\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (1.5.16)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (2.31.0)\nRequirement already satisfied: fsspec[http] in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (2023.6.0)\nRequirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (0.5.14)\nCollecting jsonschema<4.7,>=4.5.0 (from ludwig[llm])\n  Downloading jsonschema-4.6.2-py3-none-any.whl (80 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: marshmallow in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (3.20.1)\nCollecting marshmallow-jsonschema (from ludwig[llm])\n  Downloading marshmallow_jsonschema-0.13.0-py3-none-any.whl (11 kB)\nCollecting marshmallow-dataclass==8.5.4 (from ludwig[llm])\n  Downloading marshmallow_dataclass-8.5.4-py3-none-any.whl (16 kB)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (2.12.3)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (3.2.4)\nCollecting torchmetrics<=0.11.4,>=0.11.0 (from ludwig[llm])\n  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torchinfo in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (1.8.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (3.12.2)\nCollecting psutil==5.9.4 (from ludwig[llm])\n  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: protobuf==3.20.3 in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (3.20.3)\nRequirement already satisfied: py-cpuinfo==9.0.0 in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (9.0.0)\nRequirement already satisfied: gpustat in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (1.0.0)\nCollecting rich~=12.4.4 (from ludwig[llm])\n  Downloading rich-12.4.4-py3-none-any.whl (232 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.0/232.0 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (21.3)\nCollecting retry (from ludwig[llm])\n  Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\nCollecting sacremoses (from ludwig[llm])\n  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (0.1.99)\nCollecting getdaft (from ludwig[llm])\n  Downloading getdaft-0.1.15-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting xlwt (from ludwig[llm])\n  Downloading xlwt-1.3.0-py2.py3-none-any.whl (99 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.0/100.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting xlrd>=2.0.1 (from ludwig[llm])\n  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting xlsxwriter>=1.4.3 (from ludwig[llm])\n  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: openpyxl>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (3.1.2)\nCollecting pyxlsb>=1.0.8 (from ludwig[llm])\n  Downloading pyxlsb-1.0.10-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (11.0.0)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (4.9.3)\nRequirement already satisfied: html5lib in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (1.1)\nCollecting sentence-transformers (from ludwig[llm])\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting faiss-cpu (from ludwig[llm])\n  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from ludwig[llm]) (0.22.0)\nCollecting loralib (from ludwig[llm])\n  Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\nCollecting bitsandbytes<0.41.0 (from ludwig[llm])\n  Downloading bitsandbytes-0.40.2-py3-none-any.whl (92.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting peft>=0.4.0 (from ludwig[llm])\n  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-inspect>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from marshmallow-dataclass==8.5.4->ludwig[llm]) (0.9.0)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.7,>=4.5.0->ludwig[llm]) (23.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.7,>=4.5.0->ludwig[llm]) (0.19.3)\nRequirement already satisfied: et-xmlfile in /opt/conda/lib/python3.10/site-packages (from openpyxl>=3.0.7->ludwig[llm]) (1.1.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ludwig[llm]) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas!=1.1.5,>=1.0->ludwig[llm]) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas!=1.1.5,>=1.0->ludwig[llm]) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas!=1.1.5,>=1.0->ludwig[llm]) (2023.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft>=0.4.0->ludwig[llm]) (0.3.3)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<2.0->ludwig[llm]) (4.6.3)\nCollecting commonmark<0.10.0,>=0.9.0 (from rich~=12.4.4->ludwig[llm])\n  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from rich~=12.4.4->ludwig[llm]) (2.15.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy>=2.3->ludwig[llm]) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=2.3->ludwig[llm]) (1.0.4)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=2.3->ludwig[llm]) (1.0.9)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy>=2.3->ludwig[llm]) (2.0.7)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy>=2.3->ludwig[llm]) (3.0.8)\nRequirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy>=2.3->ludwig[llm]) (8.1.12)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy>=2.3->ludwig[llm]) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy>=2.3->ludwig[llm]) (2.4.7)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy>=2.3->ludwig[llm]) (2.0.9)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=2.3->ludwig[llm]) (0.9.0)\nRequirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=2.3->ludwig[llm]) (0.10.1)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy>=2.3->ludwig[llm]) (6.3.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy>=2.3->ludwig[llm]) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy>=2.3->ludwig[llm]) (68.0.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=2.3->ludwig[llm]) (3.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ludwig[llm]) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ludwig[llm]) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ludwig[llm]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ludwig[llm]) (2023.7.22)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->ludwig[llm]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->ludwig[llm]) (3.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers<4.32.0,>=4.31.0->ludwig[llm]) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<4.32.0,>=4.31.0->ludwig[llm]) (2023.6.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]->ludwig[llm]) (3.8.4)\nCollecting loguru (from getdaft->ludwig[llm])\n  Downloading loguru-0.7.1-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: six>=1.7 in /opt/conda/lib/python3.10/site-packages (from gpustat->ludwig[llm]) (1.16.0)\nRequirement already satisfied: nvidia-ml-py<=11.495.46,>=11.450.129 in /opt/conda/lib/python3.10/site-packages (from gpustat->ludwig[llm]) (11.495.46)\nRequirement already satisfied: blessed>=1.17.1 in /opt/conda/lib/python3.10/site-packages (from gpustat->ludwig[llm]) (1.20.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from html5lib->ludwig[llm]) (0.5.1)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle->ludwig[llm]) (8.0.1)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle->ludwig[llm]) (6.0.0)\nRequirement already satisfied: decorator>=3.4.2 in /opt/conda/lib/python3.10/site-packages (from retry->ludwig[llm]) (5.1.1)\nCollecting py<2.0.0,>=1.4.26 (from retry->ludwig[llm])\n  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses->ludwig[llm]) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses->ludwig[llm]) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->ludwig[llm]) (3.1.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ludwig[llm]) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ludwig[llm]) (2.20.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ludwig[llm]) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ludwig[llm]) (3.4.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ludwig[llm]) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ludwig[llm]) (2.3.7)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ludwig[llm]) (0.40.0)\nRequirement already satisfied: torchdata in /opt/conda/lib/python3.10/site-packages (from torchtext->ludwig[llm]) (0.6.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->ludwig[llm]) (9.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]->ludwig[llm]) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]->ludwig[llm]) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]->ludwig[llm]) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]->ludwig[llm]) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]->ludwig[llm]) (1.3.1)\nRequirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from blessed>=1.17.1->gpustat->ludwig[llm]) (0.2.6)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->ludwig[llm]) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->ludwig[llm]) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->ludwig[llm]) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->ludwig[llm]) (1.3.1)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.3->ludwig[llm]) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.3->ludwig[llm]) (0.1.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.7.1->marshmallow-dataclass==8.5.4->ludwig[llm]) (1.0.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->ludwig[llm]) (2.1.3)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle->ludwig[llm]) (1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->ludwig[llm]) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->ludwig[llm]) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->ludwig[llm]) (3.2.2)\nBuilding wheels for collected packages: ludwig, sacremoses, sentence-transformers\n  Building wheel for ludwig (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ludwig: filename=ludwig-0.8.2-py3-none-any.whl size=1073601 sha256=00d44d44d65b768b89b1a5f18e94dec443522a292e507da181ee9b102c0bc211\n  Stored in directory: /root/.cache/pip/wheels/56/00/82/faede8942a2a12b077d0f3dc429e2ad1b102fa6bbffe59aee5\n  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=5be1b57781ac78af971a73b92eefa4a3847e2edb6675477f00a09cac8ef5db8d\n  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=2cb4f0deb2746f6f7658fbca4f9cdb00f2d9eea33f94d1ab3f0cfaa56397e9fb\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built ludwig sacremoses sentence-transformers\nInstalling collected packages: xlwt, pyxlsb, faiss-cpu, commonmark, bitsandbytes, xlsxwriter, xlrd, sacremoses, rich, py, psutil, loralib, loguru, jsonschema, retry, transformers, torchmetrics, marshmallow-jsonschema, marshmallow-dataclass, sentence-transformers, peft, getdaft, ludwig\n  Attempting uninstall: rich\n    Found existing installation: rich 13.4.2\n    Uninstalling rich-13.4.2:\n      Successfully uninstalled rich-13.4.2\n  Attempting uninstall: psutil\n    Found existing installation: psutil 5.9.3\n    Uninstalling psutil-5.9.3:\n      Successfully uninstalled psutil-5.9.3\n  Attempting uninstall: jsonschema\n    Found existing installation: jsonschema 4.17.3\n    Uninstalling jsonschema-4.17.3:\n      Successfully uninstalled jsonschema-4.17.3\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.32.1\n    Uninstalling transformers-4.32.1:\n      Successfully uninstalled transformers-4.32.1\n  Attempting uninstall: torchmetrics\n    Found existing installation: torchmetrics 1.1.1\n    Uninstalling torchmetrics-1.1.1:\n      Successfully uninstalled torchmetrics-1.1.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 2023.621.222118 requires jupyter-server~=1.16, but you have jupyter-server 2.6.0 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2023.8.1 which is incompatible.\njupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-server 2.23.0 requires jsonschema>=4.17.3, but you have jsonschema 4.6.2 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.40.2 commonmark-0.9.1 faiss-cpu-1.7.4 getdaft-0.1.15 jsonschema-4.17.3 loguru-0.7.1 loralib-0.1.2 ludwig-0.8.2 marshmallow-dataclass-8.5.4 marshmallow-jsonschema-0.13.0 peft-0.5.0 psutil-5.9.4 py-1.11.0 pyxlsb-1.0.10 retry-0.9.2 rich-12.4.4 sacremoses-0.0.53 sentence-transformers-2.2.2 torchmetrics-0.11.4 transformers-4.31.0 xlrd-2.0.1 xlsxwriter-3.1.2 xlwt-1.3.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import getpass\nimport locale; locale.getpreferredencoding = lambda: \"UTF-8\"\nimport logging\nimport os\nimport torch\nimport yaml\n\nfrom ludwig.api import LudwigModel\n\n\nos.environ[\"HUGGING_FACE_HUB_TOKEN\"] = getpass.getpass(\"Token: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\")\nassert os.environ[\"HUGGING_FACE_HUB_TOKEN\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-04T19:27:32.706601Z","iopub.execute_input":"2023-09-04T19:27:32.706956Z","iopub.status.idle":"2023-09-04T19:28:06.994416Z","shell.execute_reply.started":"2023-09-04T19:27:32.706927Z","shell.execute_reply":"2023-09-04T19:28:06.993391Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Token: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 ·····································\n"}]},{"cell_type":"markdown","source":"**Import The Code Generation Dataset**","metadata":{}},{"cell_type":"code","source":"import numpy as np; np.random.seed(123)\nimport pandas as pd\n\ndf = pd.read_json(\"https://raw.githubusercontent.com/sahil280114/codealpaca/master/data/code_alpaca_20k.json\")\n\n# We're going to create a new column called `split` where:\n# 90% will be assigned a value of 0 -> train set\n# 5% will be assigned a value of 1 -> validation set\n# 5% will be assigned a value of 2 -> test set\n# Calculate the number of rows for each split value\ntotal_rows = len(df)\nsplit_0_count = int(total_rows * 0.9)\nsplit_1_count = int(total_rows * 0.05)\nsplit_2_count = total_rows - split_0_count - split_1_count\n\n# Create an array with split values based on the counts\nsplit_values = np.concatenate([\n    np.zeros(split_0_count),\n    np.ones(split_1_count),\n    np.full(split_2_count, 2)\n])\n\n# Shuffle the array to ensure randomness\nnp.random.shuffle(split_values)\n\n# Add the 'split' column to the DataFrame\ndf['split'] = split_values\ndf['split'] = df['split'].astype(int)\n\n#we will just take 100 rows of this dataset.\ndf = df.head(n=1000)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T20:11:34.075604Z","iopub.execute_input":"2023-09-04T20:11:34.075961Z","iopub.status.idle":"2023-09-04T20:11:34.309881Z","shell.execute_reply.started":"2023-09-04T20:11:34.075932Z","shell.execute_reply":"2023-09-04T20:11:34.308721Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T20:11:43.473805Z","iopub.execute_input":"2023-09-04T20:11:43.474167Z","iopub.status.idle":"2023-09-04T20:11:43.480618Z","shell.execute_reply.started":"2023-09-04T20:11:43.474136Z","shell.execute_reply":"2023-09-04T20:11:43.479630Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}]},{"cell_type":"code","source":"len(split_values)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T20:11:14.201113Z","iopub.execute_input":"2023-09-04T20:11:14.201515Z","iopub.status.idle":"2023-09-04T20:11:14.208494Z","shell.execute_reply.started":"2023-09-04T20:11:14.201485Z","shell.execute_reply":"2023-09-04T20:11:14.207530Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"20022"},"metadata":{}}]},{"cell_type":"markdown","source":"**Understanding The Code Alpaca Dataset**","metadata":{}},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T20:11:49.041220Z","iopub.execute_input":"2023-09-04T20:11:49.042046Z","iopub.status.idle":"2023-09-04T20:11:49.060118Z","shell.execute_reply.started":"2023-09-04T20:11:49.042007Z","shell.execute_reply":"2023-09-04T20:11:49.056567Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                                         instruction  \\\n0  Create an array of length 5 which contains all...   \n1  Formulate an equation to calculate the height ...   \n2  Write a replace method for a string class whic...   \n3  Create an array of length 15 containing number...   \n4  Write a function to find the number of distinc...   \n5  Create a nested loop to print every combinatio...   \n6  Write a function to find the maximum differenc...   \n7  Write a function to generate the nth Fibonacci...   \n8  Write a class to represent a 2D point with x a...   \n9  Write code that removes spaces from a given st...   \n\n                                               input  \\\n0                                                      \n1                                                      \n2  string = \"Hello World!\"\\nreplace_with = \"Greet...   \n3                                                      \n4  matrix = [[1, 0, 0],\\n          [1, 0, 1],\\n  ...   \n5                                                      \n6                            arr = [5, 3, 17, 11, 9]   \n7                                        < noinput >   \n8                                                      \n9                               string = \" A B C D \"   \n\n                                              output  split  \n0                             arr = [2, 4, 6, 8, 10]      0  \n1  Height of triangle = opposite side length * si...      0  \n2  def replace(self, replace_with):\\n    new_stri...      0  \n3  arr = [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33...      0  \n4  def find_num_distinct_states(matrix):\\n    sta...      0  \n5  for i in range(10):\\n    for j in range(10):\\n...      0  \n6  def max_difference(arr):\\n    max_diff = 0\\n  ...      0  \n7  def fib(n):\\n    if n == 0:\\n        return 0\\...      0  \n8  class Point:\\n    def __init__(self, x, y):\\n ...      0  \n9  def remove_spaces(string): \\n    return \"\".joi...      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>input</th>\n      <th>output</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Create an array of length 5 which contains all...</td>\n      <td></td>\n      <td>arr = [2, 4, 6, 8, 10]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Formulate an equation to calculate the height ...</td>\n      <td></td>\n      <td>Height of triangle = opposite side length * si...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Write a replace method for a string class whic...</td>\n      <td>string = \"Hello World!\"\\nreplace_with = \"Greet...</td>\n      <td>def replace(self, replace_with):\\n    new_stri...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Create an array of length 15 containing number...</td>\n      <td></td>\n      <td>arr = [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Write a function to find the number of distinc...</td>\n      <td>matrix = [[1, 0, 0],\\n          [1, 0, 1],\\n  ...</td>\n      <td>def find_num_distinct_states(matrix):\\n    sta...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Create a nested loop to print every combinatio...</td>\n      <td></td>\n      <td>for i in range(10):\\n    for j in range(10):\\n...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Write a function to find the maximum differenc...</td>\n      <td>arr = [5, 3, 17, 11, 9]</td>\n      <td>def max_difference(arr):\\n    max_diff = 0\\n  ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Write a function to generate the nth Fibonacci...</td>\n      <td>&lt; noinput &gt;</td>\n      <td>def fib(n):\\n    if n == 0:\\n        return 0\\...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Write a class to represent a 2D point with x a...</td>\n      <td></td>\n      <td>class Point:\\n    def __init__(self, x, y):\\n ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Write code that removes spaces from a given st...</td>\n      <td>string = \" A B C D \"</td>\n      <td>def remove_spaces(string): \\n    return \"\".joi...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(df)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T20:11:53.315891Z","iopub.execute_input":"2023-09-04T20:11:53.316250Z","iopub.status.idle":"2023-09-04T20:11:53.322341Z","shell.execute_reply.started":"2023-09-04T20:11:53.316218Z","shell.execute_reply":"2023-09-04T20:11:53.321325Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}]},{"cell_type":"markdown","source":"**As you can see below, the dataset is pretty balanced in terms of the number of examples of each type of instruction (also true for the full dataset with 20,000 rows)**","metadata":{}},{"cell_type":"code","source":"num_self_sufficient = (df['input'] == '').sum()\nnum_need_contex = df.shape[0] - num_self_sufficient\n\n# We are only using 100 rows of this dataset \nprint(f\"Total number of examples in the dataset: {df.shape[0]}\")\n\nprint(f\"% of examples that are self-sufficient: {round(num_self_sufficient/df.shape[0] * 100, 2)}\")\nprint(f\"% of examples that are need additional context: {round(num_need_contex/df.shape[0] * 100, 2)}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-04T20:11:55.777625Z","iopub.execute_input":"2023-09-04T20:11:55.777996Z","iopub.status.idle":"2023-09-04T20:11:55.790963Z","shell.execute_reply.started":"2023-09-04T20:11:55.777956Z","shell.execute_reply":"2023-09-04T20:11:55.789319Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Total number of examples in the dataset: 1000\n% of examples that are self-sufficient: 47.2\n% of examples that are need additional context: 52.8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**The other aspect worth noting is the average number of characters in each of the three columns instruction, input and output in the dataset. Typically, every 3-4 characters maps to a token (the basic building blocks that language models use to understand and analyze text data), and large language models have a limit on the number of tokens they can take as input.\n\n**The maximum context length for the base LLaMA-2 model is 4096 tokens. Ludwig automatically truncates texts that are too long for the model, but looking at these sequence lengths, we should be able to fine-tune on full length examples without needing any truncation.**","metadata":{}},{"cell_type":"code","source":"# Calculating the length of each cell in each column\ndf['num_characters_instruction'] = df['instruction'].apply(lambda x: len(x))\ndf['num_characters_input'] = df['input'].apply(lambda x: len(x))\ndf['num_characters_output'] = df['output'].apply(lambda x: len(x))\n\n# Show Distribution\ndf.hist(column=['num_characters_instruction', 'num_characters_input', 'num_characters_output'])\n\n# Calculating the average\naverage_chars_instruction = df['num_characters_instruction'].mean()\naverage_chars_input = df['num_characters_input'].mean()\naverage_chars_output = df['num_characters_output'].mean()\n\nprint(f'Average number of tokens in the instruction column: {(average_chars_instruction / 3):.0f}')\nprint(f'Average number of tokens in the input column: {(average_chars_input / 3):.0f}')\nprint(f'Average number of tokens in the output column: {(average_chars_output / 3):.0f}', end=\"\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-09-04T20:12:02.364855Z","iopub.execute_input":"2023-09-04T20:12:02.365217Z","iopub.status.idle":"2023-09-04T20:12:02.998436Z","shell.execute_reply.started":"2023-09-04T20:12:02.365187Z","shell.execute_reply":"2023-09-04T20:12:02.997354Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Average number of tokens in the instruction column: 23\nAverage number of tokens in the input column: 8\nAverage number of tokens in the output column: 65\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 4 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"**Declaratively Fine-Tune Large Language Models**\nFine-tuning a large language model refers to the process of further training the pre-trained model on a specific task or domain using a smaller dataset. The initial pre-training phase involves training a language model on a massive corpus of text data to learn general language patterns and representations. Fine-tuning, on the other hand, customizes the model to a specific task or domain by exposing it to task-specific data. By fine-tuning a large language model on a specific task, you leverage the pre-trained knowledge of the model while tailoring it to the nuances and requirements of your target task. This typically allows the model to perform better and achieve higher accuracy on the specific task compared to using the pretrained model by itself for your specific task.\n\n▶ **What is instruction following/tuning? Why should I do it?**\nPre-trained language models are often great at giving general answers, but they struggle when asked to follow specific instructions, especially for tasks in certain domains. To make a pre-trained model do better at these specific tasks, we can train it on examples of those tasks. This is called instruction fine-tuning. We use a dataset with pairs of {instructions, outputs} in the domain, and this helps the model learn to give the right response when given those types of instructions. This training process typically changes the underlying model weights, but there are also other ways to train it without doing this. When done correctly, this process teaches the model to understand and follow instructions it couldn't handle well before.\n\n▶ **What will this teach the model?**\nHere's an example of prompting the base model and an example prompting the fine-tuned model. The model was given all of the text until Response:, and it was supposed to continue generating an appropriate response.\n\n**Using the base model (no fine-tuning)**: 👎\n\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction: create an array of length 5 which contains all even numbers between 1 and 10.\n\n### Response:\\n\\n### Instruction: create an array of length 5 which contains all even numbers between 1 and 10.\\n\\n### Input: \\n\\n### Response:\\n\\n### Instruction: create an array of length 5 which contains all even numbers between 1 and 10.\\n\\n### Input: \\n\\n### Response:\\n\\n### Instruction: create an array of length 5 which contains all even numbers between 1 and 10.\\n\\n### Input: \\n\\n### Response:\\n\\n### Instruction: create an\n**After instruction-fine-tuning**: 👍\n\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction: create an array of length 5 which contains all even numbers between 1 and 10.\n\n### Response: array = [2, 4, 6, 8, 10]\nThe base model does not know how to follow-instructions and answer the question for our task, so just repeats the inputs we passed in until the token limit is hit. Our fine-tuned model should be able to respond back correctly (these are actual outputs from a model we fine-tuned).","metadata":{}},{"cell_type":"markdown","source":"There are three different fine-tuning approaches in Ludwig:\n\n1)Full Fine-Tuning:\nInvolves training the entire pre-trained model on new data from scratch.\nAll model layers and parameters are updated during fine-tuning.\nCan lead to high accuracy but requires a significant amount of computational resources and time.\nRuns the risk of catastrophic forgetting: occasionally, since we are updating all of the weights in the model, this process can lead to the algorithm inadvertently losing knowledge of its past tasks, i.e., the knowledge it gained during pretraining. The outcome may vary, with the algorithm experiencing heightened error margins in some cases, while in others, it might completely erase the memory of a specific task leading to terrible performance.\nBest suited when the target task is significantly different from the original pre-training task.\n\n2)Parameter Efficient Fine-Tuning (PEFT), e.g. LoRA:\nFocuses on updating only a subset of the model's parameters.\nOften involves freezing certain layers or parts of the model to avoid catastrophic forgetting, or inserting additional layers that are trainable while keeping the original model's weights frozen.\nCan result in faster fine-tuning with fewer computational resources, but might sacrifice some accuracy compared to full fine-tuning.\nIncludes methods like LoRA, AdaLoRA and Adaption Prompt (LLaMA Adapter)\nSuitable when the new task shares similarities with the original pre-training task.\n\n3)Quantization-Based Fine-Tuning (QLoRA):\nInvolves reducing the precision of model parameters (e.g., converting 32-bit floating-point values to 8-bit or 4-bit integers). This reduces the amount of CPU and GPU memory required by either 4x if using 8-bit integers, or 8x if using 4-bit integers.\nTypically, since we're changing the weights to 8 or 4 bit integers, we will lose some precision/performance.\nThis can lead to reduced memory usage and faster inference on hardware with reduced precision support.\nParticularly useful when deploying models on resource-constrained devices, such as mobile phones or edge devices.","metadata":{}},{"cell_type":"markdown","source":"Today, we're going to fine-tune using method 3 since we only have access to a single T4 GPU with 16GiB of GPU VRAM on Colab or kaggle. If you have more compute available, give LoRA based fine-tuning or full fine-tuning a try! Typically this requires 4 GPUs with 24GiB of GPU VRAM on a single node multi-GPU cluster and fine-tuning Deepspeeed.\n\nTo do this, the new parameters we're introducing are:\n\nadapter: The PEFT method we want to use\nquantization: Load the weights in int4 or int8 to reduce memory overhead.\ntrainer: We enable the finetune trainer and can configure a variety of training parameters such as epochs and learning rate","metadata":{}},{"cell_type":"code","source":"model = None\nclear_cache()\n\nqlora_fine_tuning_config = yaml.safe_load(\n\"\"\"\nmodel_type: llm\nbase_model: meta-llama/Llama-2-7b-hf\n\ninput_features:\n  - name: instruction\n    type: text\n\noutput_features:\n  - name: output\n    type: text\n\nprompt:\n  template: >-\n    Below is an instruction that describes a task, paired with an input\n    that provides further context. Write a response that appropriately\n    completes the request.\n\n    ### Instruction: {instruction}\n\n    ### Input: {input}\n\n    ### Response:\n\ngeneration:\n  temperature: 0.1\n  max_new_tokens: 512\n\nadapter:\n  type: lora\n\nquantization:\n  bits: 4\n\ntrainer:\n  type: finetune\n  epochs: 5\n  batch_size: 1\n  eval_batch_size: 2\n  gradient_accumulation_steps: 16\n  learning_rate: 0.0001\n  optimizer:\n    type: adam\n    params:\n      eps: 1.e-8\n      betas:\n        - 0.9\n        - 0.999\n      weight_decay: 0\n  learning_rate_scheduler:\n    warmup_fraction: 0.03\n    reduce_on_plateau: 0\n\n\n\"\"\"\n)\n\nmodel = LudwigModel(config=qlora_fine_tuning_config, logging_level=logging.INFO)\nresults = model.train(dataset=df)","metadata":{"execution":{"iopub.status.busy":"2023-09-04T20:12:14.283860Z","iopub.execute_input":"2023-09-04T20:12:14.285019Z","iopub.status.idle":"2023-09-04T21:17:13.067957Z","shell.execute_reply.started":"2023-09-04T20:12:14.284976Z","shell.execute_reply":"2023-09-04T21:17:13.066920Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82d55506a5244ff3b820fca4ef23899c"}},"metadata":{}},{"name":"stdout","text":"Training:  17%|█▋        | 61/350 [03:46<17:52,  3.71s/it, loss=0.197]\ntrainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199\nEvaluation valid: 100%|██████████| 50/50 [01:20<00:00,  1.60s/it]=0.065]   \nEvaluation test : 100%|██████████| 100/100 [04:00<00:00,  2.41s/it]\nEvaluation valid: 100%|██████████| 50/50 [01:20<00:00,  1.62s/it]s=0.132]   \nEvaluation test : 100%|██████████| 100/100 [04:01<00:00,  2.41s/it]\nEvaluation valid: 100%|██████████| 50/50 [01:22<00:00,  1.64s/it]s=0.0335]    \nEvaluation test : 100%|██████████| 100/100 [04:02<00:00,  2.42s/it]\nEvaluation valid: 100%|██████████| 50/50 [01:21<00:00,  1.64s/it]s=0.0208]    \nEvaluation test : 100%|██████████| 100/100 [04:01<00:00,  2.42s/it]\nEvaluation valid: 100%|██████████| 50/50 [01:20<00:00,  1.62s/it]s=0.0113]   \nEvaluation test : 100%|██████████| 100/100 [04:00<00:00,  2.41s/it]\nTraining: 100%|██████████| 3500/3500 [1:03:30<00:00,  1.09s/it, loss=0.0113]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Perform Inference**\n\nWe can now use the model we fine-tuned above to make predictions on some test examples to see whether fine-tuning the large language model improve its ability to follow instructions/the tasks we're asking it to perform.","metadata":{}},{"cell_type":"code","source":"test_examples = pd.DataFrame([\n      {\n            \"instruction\": \"Create an array of length 5 which contains all even numbers between 1 and 10.\",\n            \"input\": ''\n      },\n      {\n            \"instruction\": \"Create an array of length 15 containing numbers divisible by 3 up to 45.\",\n            \"input\": \"\",\n      },\n      {\n            \"instruction\": \"Create a nested loop to print every combination of numbers between 0-9\",\n            \"input\": \"\"\n      },\n      {\n            \"instruction\": \"Generate a function that computes the sum of the numbers in a given list\",\n            \"input\": \"\",\n      },\n      {\n            \"instruction\": \"Create a class to store student names, ages and grades.\",\n            \"input\": \"\",\n      },\n      {\n            \"instruction\": \"Print out the values in the following dictionary.\",\n            \"input\": \"my_dict = {\\n  'name': 'John Doe',\\n  'age': 32,\\n  'city': 'New York'\\n}\",\n      },\n])\n\npredictions = model.predict(test_examples)[0]\nfor input_with_prediction in zip(test_examples['instruction'], test_examples['input'], predictions['output_response']):\n  print(f\"Instruction: {input_with_prediction[0]}\")\n  print(f\"Input: {input_with_prediction[1]}\")\n  print(f\"Generated Output: {input_with_prediction[2][0]}\")\n  print(\"\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-09-04T21:17:45.393478Z","iopub.execute_input":"2023-09-04T21:17:45.394123Z","iopub.status.idle":"2023-09-04T21:18:17.597460Z","shell.execute_reply.started":"2023-09-04T21:17:45.394088Z","shell.execute_reply":"2023-09-04T21:18:17.596523Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"Prediction: 100%|██████████| 1/1 [00:29<00:00, 29.89s/it]\nInstruction: Create an array of length 5 which contains all even numbers between 1 and 10.\nInput: \nGenerated Output: arr = [2, 4, 6, 8, 10]\n\n\n\nInstruction: Create an array of length 15 containing numbers divisible by 3 up to 45.\nInput: \nGenerated Output: arr = [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45]\n\n\n\nInstruction: Create a nested loop to print every combination of numbers between 0-9\nInput: \nGenerated Output: for i in range(10):\n    for j in range(10):\n        print(i, j)\n\n\n\nInstruction: Generate a function that computes the sum of the numbers in a given list\nInput: \nGenerated Output: def sum_list(list):\n    total = 0\n    for num in list:\n        total += num\n    return total\n\n\n\nInstruction: Create a class to store student names, ages and grades.\nInput: \nGenerated Output: class student:\n    def __init__(self, name, age, grade):\n        self.name = name\n        self.age = age\n        self.grade = grade\n\n    def get_name(self):\n        return self.name\n\n    def get_age(self):\n        return self.age\n\n    def get_grade(self):\n        return self.grade\n\n\n\nInstruction: Print out the values in the following dictionary.\nInput: my_dict = {\n  'name': 'John Doe',\n  'age': 32,\n  'city': 'New York'\n}\nGenerated Output: my_dict = {\n  'name': 'john doe',\n  'age': 32,\n  'city': 'new york'\n}\nfor key in my_dict:\n  print(f\"{key}: {my_dict[key]}\")\n\n\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/ludwig/features/feature_utils.py:102: RuntimeWarning: divide by zero encountered in log\n  return np.sum(np.log(sequence_probabilities))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Observations From QLoRA Fine-Tuning 🔎\nEven when we just fine-tune the model on 100 examples from our dataset (which only takes about 4 minutes), it significantly improves the model on our task 🔥\nThe answers are not perfect when we just use 100 examples, but if we inspect the logic in the response, we can see that it is 95% of the way there. This is SIGNIFICANTLY better than before - there is no repetition and the actual code aspects of the answers are all correct.\nThe partial errors such as sierp instead of arrray etc indicates that we need to train on a larger amount of data for the model to better learn how to follow instructions and not make these kinds of mistakes.","metadata":{}}]}